---

title: Core


keywords: fastai
sidebar: home_sidebar

summary: "fastai and Huggingface transformers"
description: "fastai and Huggingface transformers"
nb_path: "nbs/01_core.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/01_core.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pretrained_weights</span> <span class="o">=</span> <span class="s2">&quot;bert-base-uncased&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">pretrained_weights</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;test_data.csv&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="TransformersTokenizer" class="doc_header"><code>class</code> <code>TransformersTokenizer</code><a href="https://github.com/kbressem/fastai_transformer/tree/master/fastai_transformer/core.py#L18" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>TransformersTokenizer</code>(<strong><code>tokenizer</code></strong>, <strong><code>seq_len</code></strong>, <strong><code>truncation</code></strong>) :: <code>Transform</code></p>
</blockquote>
<p>A wrapper for the tokenizer from Huggingface transformers
Arguments:
    tokenizer: the tokenizer class from Hugginface transformers
    seq_len: the max length ot the sequences
    truncation: if the sequences exceeding seq_len should be truncated
                (should be true if seq_len is provided)</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="TextBlockWithCustomTokenizer" class="doc_header"><code>class</code> <code>TextBlockWithCustomTokenizer</code><a href="https://github.com/kbressem/fastai_transformer/tree/master/fastai_transformer/core.py#L60" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>TextBlockWithCustomTokenizer</code>(<strong><code>tok</code></strong>, <strong><code>is_lm</code></strong>, <strong><code>seq_len</code></strong>, <strong><code>backwards</code></strong>=<em><code>False</code></em>, <strong>**<code>kwargs</code></strong>) :: <code>TransformBlock</code></p>
</blockquote>
<p>a TransformBlock with custom Tokenizer from Hugginface transformers</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="None" class="doc_header"><code>None</code><a href="" class="source_link" style="float:right">[source]</a></h4>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span> <span class="o">=</span> <span class="n">TextDataLoaders</span><span class="o">.</span><span class="n">from_df_with_custom_tok</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">custom_tok</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">bs</span> <span class="o">=</span> <span class="mi">8</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">max_n</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>category</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>yes, i was lucky enough to see the long - running original production of michael bennett's hit musical. it was an amazing experience and i paid to see the movie when it hit theatres back in 1985. it is awful. almost everything fails. first off, attenborough ( a fine actor, a good director with the right material ) is a sorry</td>
      <td>neg</td>
    </tr>
    <tr>
      <th>1</th>
      <td>i thought the film could be a bit more complex, in a psychological sense perhaps, but the action and voice acting were top notch. the animation was heavy cg in many scenes, but very good ones at that. this is one of the batman returns / forever type films, which include romances and the conflicts of wayne and motives for dating. 007</td>
      <td>pos</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="DropOutput" class="doc_header"><code>class</code> <code>DropOutput</code><a href="https://github.com/kbressem/fastai_transformer/tree/master/fastai_transformer/core.py#L89" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>DropOutput</code>(<strong><code>after_create</code></strong>=<em><code>None</code></em>, <strong><code>before_fit</code></strong>=<em><code>None</code></em>, <strong><code>before_epoch</code></strong>=<em><code>None</code></em>, <strong><code>before_train</code></strong>=<em><code>None</code></em>, <strong><code>before_batch</code></strong>=<em><code>None</code></em>, <strong><code>after_pred</code></strong>=<em><code>None</code></em>, <strong><code>after_loss</code></strong>=<em><code>None</code></em>, <strong><code>before_backward</code></strong>=<em><code>None</code></em>, <strong><code>before_step</code></strong>=<em><code>None</code></em>, <strong><code>after_cancel_step</code></strong>=<em><code>None</code></em>, <strong><code>after_step</code></strong>=<em><code>None</code></em>, <strong><code>after_cancel_batch</code></strong>=<em><code>None</code></em>, <strong><code>after_batch</code></strong>=<em><code>None</code></em>, <strong><code>after_cancel_train</code></strong>=<em><code>None</code></em>, <strong><code>after_train</code></strong>=<em><code>None</code></em>, <strong><code>before_validate</code></strong>=<em><code>None</code></em>, <strong><code>after_cancel_validate</code></strong>=<em><code>None</code></em>, <strong><code>after_validate</code></strong>=<em><code>None</code></em>, <strong><code>after_cancel_epoch</code></strong>=<em><code>None</code></em>, <strong><code>after_epoch</code></strong>=<em><code>None</code></em>, <strong><code>after_cancel_fit</code></strong>=<em><code>None</code></em>, <strong><code>after_fit</code></strong>=<em><code>None</code></em>) :: <code>Callback</code></p>
</blockquote>
<p>Drops some of the output form the transformes model, which is not needed for fastai</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="create_transformer_classification_model" class="doc_header"><code>create_transformer_classification_model</code><a href="https://github.com/kbressem/fastai_transformer/tree/master/fastai_transformer/core.py#L94" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>create_transformer_classification_model</code>(<strong><code>model</code></strong>, <strong><code>n_out</code></strong>, <strong><code>model_name</code></strong>)</p>
</blockquote>
<p>creates a classification model from hugginface transformers</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="transformers_classifier_learner" class="doc_header"><code>transformers_classifier_learner</code><a href="https://github.com/kbressem/fastai_transformer/tree/master/fastai_transformer/core.py#L117" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>transformers_classifier_learner</code>(<strong><code>dls</code></strong>, <strong><code>arch</code></strong>, <strong><code>seq_len</code></strong>=<em><code>72</code></em>, <strong><code>backwards</code></strong>=<em><code>False</code></em>, <strong><code>model_name</code></strong>=<em><code>None</code></em>, <strong><code>n_out</code></strong>=<em><code>None</code></em>, <strong><code>y_range</code></strong>=<em><code>None</code></em>, <strong><code>cbs</code></strong>=<em><code>None</code></em>, <strong><code>loss_func</code></strong>=<em><code>None</code></em>, <strong><code>opt_func</code></strong>=<em><code>Adam</code></em>, <strong><code>lr</code></strong>=<em><code>0.001</code></em>, <strong><code>splitter</code></strong>=<em><code>trainable_params</code></em>, <strong><code>metrics</code></strong>=<em><code>None</code></em>, <strong><code>path</code></strong>=<em><code>None</code></em>, <strong><code>model_dir</code></strong>=<em><code>'models'</code></em>, <strong><code>wd</code></strong>=<em><code>None</code></em>, <strong><code>wd_bn_bias</code></strong>=<em><code>False</code></em>, <strong><code>train_bn</code></strong>=<em><code>True</code></em>, <strong><code>moms</code></strong>=<em><code>(0.95, 0.85, 0.95)</code></em>)</p>
</blockquote>
<p>creates a Learner class for classification using Huggingface transformers</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="print_multilabel_classification_report" class="doc_header"><code>print_multilabel_classification_report</code><a href="https://github.com/kbressem/fastai_transformer/tree/master/fastai_transformer/core.py#L133" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>print_multilabel_classification_report</code>()</p>
</blockquote>
<p>Calculates common classification metrics for each label separately.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">transformers_classifier_learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> 
                                        <span class="n">model_name</span><span class="o">=</span><span class="n">pretrained_weights</span><span class="p">,</span> 
                                        <span class="n">metrics</span> <span class="o">=</span> <span class="n">accuracy</span><span class="p">,</span> 
                                        <span class="n">cbs</span> <span class="o">=</span> <span class="p">[</span><span class="n">SaveModelCallback</span><span class="p">(),</span> <span class="n">EarlyStoppingCallback</span><span class="p">(</span><span class="n">patience</span><span class="o">=</span><span class="mi">5</span><span class="p">)])</span><span class="o">.</span><span class="n">to_fp16</span><span class="p">()</span>
<span class="n">learn</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: [&#39;cls.predictions.bias&#39;, &#39;cls.predictions.transform.dense.weight&#39;, &#39;cls.predictions.transform.dense.bias&#39;, &#39;cls.predictions.decoder.weight&#39;, &#39;cls.seq_relationship.weight&#39;, &#39;cls.seq_relationship.bias&#39;, &#39;cls.predictions.transform.LayerNorm.weight&#39;, &#39;cls.predictions.transform.LayerNorm.bias&#39;]
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: [&#39;classifier.weight&#39;, &#39;classifier.bias&#39;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">,</span> <span class="n">wd</span> <span class="o">=</span> <span class="mf">1e-4</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.688082</td>
      <td>0.656907</td>
      <td>0.680000</td>
      <td>00:05</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.699804</td>
      <td>0.764321</td>
      <td>0.540000</td>
      <td>00:05</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.703906</td>
      <td>0.691027</td>
      <td>0.540000</td>
      <td>00:05</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Better model found at epoch 0 with valid_loss value: 0.6569069623947144.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

